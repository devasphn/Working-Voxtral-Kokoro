# Environment Variables Template for Voxtral Model (VAD + ASR + LLM)
# Copy this file to .env and fill in your actual values

# HuggingFace Authentication (REQUIRED)
HF_TOKEN=your_huggingface_token_here

# CUDA and GPU Configuration
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
TOKENIZERS_PARALLELISM=false

# System Optimization
OMP_NUM_THREADS=8
MKL_NUM_THREADS=8

# Model Configuration
MODEL_CACHE_DIR=./model_cache
MODEL_LOAD_TIMEOUT=300
MAX_MODEL_LEN=2048
GPU_MEMORY_UTILIZATION=0.8

# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_HTTP_PORT=8000
SERVER_HEALTH_PORT=8005

# Performance Tuning
CHUNK_SIZE=512
SAMPLE_RATE=16000
LATENCY_TARGET=300
MEMORY_FRACTION=0.9

# Optimization Flags
ENABLE_TORCH_COMPILE=true
ENABLE_FLASH_ATTENTION=true
ENABLE_QUANTIZATION=true
ENABLE_KV_CACHE=true

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=./logs/voxtral_streaming.log

# Security Note:
# Never commit the actual .env file with real tokens to version control
# Always use placeholder values in documentation and setup files
# Keep your actual tokens secure and private
